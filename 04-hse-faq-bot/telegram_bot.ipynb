{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install aiogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Mr95m56PoD",
        "outputId": "26b901e7-e971-461b-86ba-4b5bcb32d0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiogram\n",
            "  Downloading aiogram-3.18.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting aiofiles<24.2,>=23.2.1 (from aiogram)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp<3.12,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from aiogram) (3.11.13)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from aiogram) (2025.1.31)\n",
            "Collecting magic-filter<1.1,>=1.0.12 (from aiogram)\n",
            "  Downloading magic_filter-1.0.12-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic<2.11,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from aiogram) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions<=5.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from aiogram) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.12,>=3.9.0->aiogram) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.11,>=2.4.1->aiogram) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.11,>=2.4.1->aiogram) (2.27.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<3.12,>=3.9.0->aiogram) (3.10)\n",
            "Downloading aiogram-3.18.0-py3-none-any.whl (612 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.8/612.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: magic-filter, aiofiles, aiogram\n",
            "Successfully installed aiofiles-24.1.0 aiogram-3.18.0 magic-filter-1.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTIGwKrw527z",
        "outputId": "7b9d8d98-ba85-4b11-b680-decbfa8aa5b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram.dispatcher:Received SIGINT signal\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import logging\n",
        "import json\n",
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from aiogram import Bot, Dispatcher, types\n",
        "from aiogram.filters import Command\n",
        "from aiogram.types import ReplyKeyboardMarkup, KeyboardButton, InputFile\n",
        "import requests\n",
        "\n",
        "API_TOKEN = \"ТУТ МОГ БЫТЬ ВАШ TOKEN\"\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "dp = Dispatcher()\n",
        "\n",
        "with open('faq.json', encoding='utf-8') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "faq_questions = [item[\"question\"] for item in data.get(\"faq\", [])]\n",
        "faq_answers = [item[\"answer\"] for item in data.get(\"faq\", [])]\n",
        "\n",
        "# TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(faq_questions)\n",
        "\n",
        "# Word2Vec\n",
        "sentences = [q.split() for q in faq_questions]\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def sentence_vector(sentence, model):\n",
        "    words = sentence.split()\n",
        "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "faq_vectors = np.array([sentence_vector(q, model) for q in faq_questions])\n",
        "\n",
        "# Кнопки\n",
        "kb = [\n",
        "    [\n",
        "        KeyboardButton(text=\"О компании\"),\n",
        "        KeyboardButton(text=\"Пожаловаться\")\n",
        "    ]\n",
        "]\n",
        "\n",
        "keyboard = ReplyKeyboardMarkup(\n",
        "    keyboard=kb,\n",
        "    resize_keyboard=True,\n",
        "    input_field_placeholder=\"Выберите действие\"\n",
        ")\n",
        "\n",
        "@dp.message(Command(\"start\"))\n",
        "async def start_command(message: types.Message):\n",
        "    await message.answer(\"С чем вам помочь?\", reply_markup=keyboard)\n",
        "\n",
        "\n",
        "@dp.message(lambda message: message.text == \"О компании\")\n",
        "async def about_company(message: types.Message):\n",
        "    await message.answer(\"Наша компания занимается доставкой товаров по всей стране.\")\n",
        "\n",
        "\n",
        "@dp.message(lambda message: message.text == \"Пожаловаться\")\n",
        "async def operator(message: types.Message):\n",
        "    await message.answer(\"Пожалуйста, отправьте в чат скрин ошибки\")\n",
        "\n",
        "@dp.message(lambda message: message.document)\n",
        "async def handle_docs(message: types.Message):\n",
        "    # Асинхронная функция, которая обрабатывает полученное сообщение\n",
        "    document = message.document\n",
        "    # Извлекаем информацию о документе из сообщения\n",
        "    file_info = f\"Файл: {document.file_name}\\nРазмер: {document.file_size} байт. \\nВаш запрос передан специалисту \" # Создаем строку с информацией о файле (имя и размер)\n",
        "    await message.answer(file_info)\n",
        "\n",
        "def get_best_answer_tfidf(query, tfidf_matrix, vectorizer, faq_answers):\n",
        "    query_vec = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(query_vec, tfidf_matrix)\n",
        "    best_match_idx = similarities.argmax()\n",
        "    return faq_answers[best_match_idx]\n",
        "\n",
        "def get_best_answer_word2vec(query, faq_vectors, model, faq_answers):\n",
        "    query_vector = sentence_vector(query, model).reshape(1, -1)\n",
        "    similarities = cosine_similarity(query_vector, faq_vectors)\n",
        "    best_match_idx = similarities.argmax()\n",
        "    return faq_answers[best_match_idx]\n",
        "\n",
        "@dp.message()\n",
        "async def answer_faq(message: types.Message):\n",
        "    query = message.text.lower()\n",
        "\n",
        "    # Получаем ответы от обоих методов\n",
        "    best_answer_tfidf = get_best_answer_tfidf(query, tfidf_matrix, vectorizer, faq_answers)\n",
        "    best_answer_word2vec = get_best_answer_word2vec(query, faq_vectors, model, faq_answers)\n",
        "\n",
        "    # Сравниваем косинусные сходства\n",
        "    query_vec_tfidf = vectorizer.transform([query])\n",
        "    query_vector_word2vec = sentence_vector(query, model).reshape(1, -1)\n",
        "\n",
        "    similarities_tfidf = cosine_similarity(query_vec_tfidf, tfidf_matrix).max()\n",
        "    similarities_word2vec = cosine_similarity(query_vector_word2vec, faq_vectors).max()\n",
        "\n",
        "    # Выбираем лучший ответ на основе максимального косинусного сходства\n",
        "    if similarities_tfidf > similarities_word2vec:\n",
        "        response = best_answer_tfidf\n",
        "    else:\n",
        "        response = best_answer_word2vec\n",
        "\n",
        "    await message.answer(response)\n",
        "\n",
        "async def main():\n",
        "    bot = Bot(token=API_TOKEN)\n",
        "    await dp.start_polling(bot)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ]
    }
  ]
}